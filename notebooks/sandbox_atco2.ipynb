{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68ac048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from transformers import AutoModelForCTC, Wav2Vec2Processor, Wav2Vec2ProcessorWithLM\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import torchaudio.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba0c7726",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "USE_LM = False\n",
    "MODEL_ID = \"Jzuluaga/wav2vec2-xls-r-300m-en-atc-atcosim\"\n",
    "\n",
    "model = AutoModelForCTC.from_pretrained(MODEL_ID)\n",
    "\n",
    "if USE_LM:\n",
    "    processor = Wav2Vec2ProcessorWithLM.from_pretrained(MODEL_ID)\n",
    "else:\n",
    "    processor = Wav2Vec2Processor.from_pretrained(MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b16bb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[transcribe] Chunk 1/20: ['ahooimo you']\n",
      "[transcribe] Chunk 2/20: ['opoyoubruo']\n",
      "[transcribe] Chunk 3/20: ['']\n",
      "[transcribe] Chunk 4/20: ['']\n",
      "[transcribe] Chunk 5/20: ['o']\n",
      "[transcribe] Chunk 6/20: ['oe']\n",
      "[transcribe] Chunk 7/20: ['hauo']\n",
      "[transcribe] Chunk 8/20: ['oo']\n",
      "[transcribe] Chunk 9/20: ['']\n",
      "[transcribe] Chunk 10/20: ['oo']\n",
      "[transcribe] Chunk 11/20: ['o']\n",
      "[transcribe] Chunk 12/20: ['']\n",
      "[transcribe] Chunk 13/20: ['oo']\n",
      "[transcribe] Chunk 14/20: ['eoyo']\n",
      "[transcribe] Chunk 15/20: ['om']\n",
      "[transcribe] Chunk 16/20: ['eoo']\n",
      "[transcribe] Chunk 17/20: ['p']\n",
      "[transcribe] Chunk 18/20: ['hagoook']\n",
      "[transcribe] Chunk 19/20: ['haoboyoo']\n",
      "[transcribe] Chunk 20/20: ['geieom oo']\n"
     ]
    }
   ],
   "source": [
    "chunk_dir = Path(\"chunks/EHAA-eham_rdr_124230-Jul-29-2025-1000Z\")\n",
    "chunk_files = sorted(chunk_dir.glob(\"*.wav\"))\n",
    "\n",
    "results = []\n",
    "for i, path in enumerate(chunk_files):\n",
    "    waveform, sample_rate = torchaudio.load(path)\n",
    "\n",
    "    # Resample if needed\n",
    "    if sample_rate != 16000:\n",
    "        resampler = T.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "        waveform = resampler(waveform)\n",
    "        sample_rate = 16000\n",
    "\n",
    "    input_values = processor(waveform.numpy(), return_tensors=\"pt\", sampling_rate=16000).input_values\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "\n",
    "    if USE_LM:\n",
    "        transcription = processor.batch_decode(logits.numpy()).text\n",
    "    else:\n",
    "        pred_ids = torch.argmax(logits, dim=-1)\n",
    "        transcription = processor.batch_decode(pred_ids)\n",
    "    \n",
    "    results.append(f\"{i+1} {transcription}\")\n",
    "    print(f\"[transcribe] Chunk {i+1}/{len(chunk_files)}: {transcription}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90c096c",
   "metadata": {},
   "source": [
    "# Named-entity recognition task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ed2fa7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f45bb68d4c4b029cbeca515ff06eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/406 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba649bb3697d4241b897868e331c2d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd33c28386fd4150bdcbabd418e5ea7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb1956b7d1d4cfc921b259eaf515ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef45af9c92c34cb49a33d47c04d5be7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af72d3857264ce5991b5585da210b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Jzuluaga/bert-base-ner-atc-en-atco2-1h\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Jzuluaga/bert-base-ner-atc-en-atco2-1h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8059ec52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'command',\n",
       "  'score': np.float32(0.9996774),\n",
       "  'word': 'contact',\n",
       "  'start': 5,\n",
       "  'end': 12},\n",
       " {'entity_group': 'callsign',\n",
       "  'score': np.float32(0.9311979),\n",
       "  'word': 'austrian information',\n",
       "  'start': 13,\n",
       "  'end': 33},\n",
       " {'entity_group': 'callsign',\n",
       "  'score': np.float32(0.9998721),\n",
       "  'word': 'one one nine seven five',\n",
       "  'start': 34,\n",
       "  'end': 57},\n",
       " {'entity_group': 'callsign',\n",
       "  'score': np.float32(0.9138362),\n",
       "  'word': 'six three alfa',\n",
       "  'start': 67,\n",
       "  'end': 81}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline('ner', model=model, tokenizer=tokenizer, aggregation_strategy=\"first\")\n",
    "nlp(\"yeah contact austrian information one one nine seven five good bye six three alfa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e2986a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
